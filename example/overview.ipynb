{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:860: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import nlpaug.augmenter.char as nac\n",
    "import nlpaug.augmenter.word as naw\n",
    "import nlpaug.flow as naf\n",
    "\n",
    "from nlpaug.util import Action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token:['The', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog']\n"
     ]
    }
   ],
   "source": [
    "text = 'The quick brown fox jumps over the lazy dog'\n",
    "tokens = text.split(' ')\n",
    "print('Token:{}'.format(tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Character Augmentation\n",
    "\n",
    "Augmenting data in character level. Possible scenarios include image to text and chatbot. During recognizing text from image, we need to optical character recognition (OCR) model to achieve it but OCR introduces some errors such as recognizing \"o\" and \"0\". `OCRAug` simulate these errors to perform the data augmentation. For chatbot, we still have typo even though most of application comes with word correction. Therefore, `QWERTYAug` is introduced to similar this kind of errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Substitute character by pre-defined OCR error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The --> The\n",
      "quick --> quick\n",
      "brown --> bkown\n",
      "fox --> fox\n",
      "jumps --> jumps\n",
      "over --> ovek\n",
      "the --> the\n",
      "lazy --> lazy\n",
      "dog --> do9\n"
     ]
    }
   ],
   "source": [
    "aug = nac.OcrAug()\n",
    "\n",
    "for token in tokens:\n",
    "    print('{} --> {}'.format(token, aug.augment([token])[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Substitute character by keyboard distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The --> Th2\n",
      "quick --> quic.\n",
      "brown --> browM\n",
      "fox --> eox\n",
      "jumps --> jumpE\n",
      "over --> kver\n",
      "the --> tne\n",
      "lazy --> laXy\n",
      "dog --> d(g\n"
     ]
    }
   ],
   "source": [
    "aug = nac.QwertyAug()\n",
    "\n",
    "for token in tokens:\n",
    "    print('{} --> {}'.format(token, aug.augment([token])[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insert character randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The --> 9The\n",
      "quick --> quiack\n",
      "brown --> brOown\n",
      "fox --> feox\n",
      "jumps --> jumcps\n",
      "over --> ovKer\n",
      "the --> thee\n",
      "lazy --> l&azy\n",
      "dog --> do&g\n"
     ]
    }
   ],
   "source": [
    "aug = nac.RandomCharAug(action=Action.INSERT)\n",
    "\n",
    "for token in tokens:\n",
    "    print('{} --> {}'.format(token, aug.augment([token])[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Substitute character randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The --> Th$\n",
      "quick --> qu4ck\n",
      "brown --> brnwn\n",
      "fox --> fox\n",
      "jumps --> jumpC\n",
      "over --> oveu\n",
      "the --> &he\n",
      "lazy --> lazH\n",
      "dog --> dUg\n"
     ]
    }
   ],
   "source": [
    "aug = nac.RandomCharAug(action=Action.SUBSTITUTE)\n",
    "\n",
    "for token in tokens:\n",
    "    print('{} --> {}'.format(token, aug.augment([token])[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete character randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The --> Th\n",
      "quick --> uick\n",
      "brown --> bron\n",
      "fox --> ox\n",
      "jumps --> umps\n",
      "over --> oer\n",
      "the --> te\n",
      "lazy --> azy\n",
      "dog --> og\n"
     ]
    }
   ],
   "source": [
    "aug = nac.RandomCharAug(action=Action.DELETE)\n",
    "\n",
    "for token in tokens:\n",
    "    print('{} --> {}'.format(token, aug.augment([token])[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Augmentation\n",
    "\n",
    "Besides character augmentation, word level is important as well. We make use of word2vec (Mikolov et al., 2013), GloVe (Pennington et al., 2014) and wordnet to insert and substitute similar word. `Word2vecAug` and `GloVeAug` use word embeddings to find most similar group of words to replace original word. On the other hand, wordnet use statistics way to find the similar group of words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insert word randomly by word2vec similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog'] --> ['The', 'Ralphs_Safeway', 'quick', 'brown', 'fox', 'jumps', 'Brunswig', 'over', 'the', 'lazy', 'dog']\n"
     ]
    }
   ],
   "source": [
    "aug = naw.Word2vecAug(\n",
    "    model_path=os.environ.get(\"MODEL_DIR\")+'GoogleNews-vectors-negative300.bin',\n",
    "    action=Action.INSERT)\n",
    "\n",
    "print('{} --> {}'.format(tokens, aug.augment(tokens)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Substitue word by word2vec similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog'] --> ['The', 'quick', 'brown', 'fox', 'jumps', 'over', 'in', 'lazy', 'pit_bull']\n"
     ]
    }
   ],
   "source": [
    "aug = naw.Word2vecAug(\n",
    "    model_path=os.environ.get(\"MODEL_DIR\")+'GoogleNews-vectors-negative300.bin',\n",
    "    action=Action.SUBSTITUTE)\n",
    "\n",
    "print('{} --> {}'.format(tokens, aug.augment(tokens)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insert word randomly by GloVe similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog'] --> ['The', 'quick', 'brown', 'fox', 'jumps', 'ista', 'over', 'the', 'lazy', 'hirschson', 'dog']\n"
     ]
    }
   ],
   "source": [
    "aug = naw.GloVeAug(\n",
    "    model_path=os.environ.get(\"MODEL_DIR\")+'glove.6B.50d.txt',\n",
    "    action=Action.INSERT)\n",
    "\n",
    "print('{} --> {}'.format(tokens, aug.augment(tokens)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Substitue word by GloVe similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog'] --> ['The', 'easy', 'gray', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog']\n"
     ]
    }
   ],
   "source": [
    "aug = naw.GloVeAug(\n",
    "    model_path=os.environ.get(\"MODEL_DIR\")+'glove.6B.50d.txt',\n",
    "    action=Action.SUBSTITUTE)\n",
    "\n",
    "print('{} --> {}'.format(tokens, aug.augment(tokens)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Substitue word by synonym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog'] --> ['The', 'quick', 'Brown_University', 'fox', 'jumps', 'concluded', 'the', 'lazy', 'dog']\n"
     ]
    }
   ],
   "source": [
    "aug = naw.SynonymAug()\n",
    "\n",
    "print('{} --> {}'.format(tokens, aug.augment(tokens)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete word randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens: 9 ['The', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog']\n",
      "results: 7 ['The', 'quick', 'brown', 'fox', 'jumps', 'over', 'the']\n",
      "['The', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog'] --> ['The', 'quick', 'brown', 'fox', 'jumps', 'over', 'the']\n"
     ]
    }
   ],
   "source": [
    "aug = naw.RandomWordAug()\n",
    "\n",
    "print('{} --> {}'.format(tokens, aug.augment(tokens)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flow Augmentation\n",
    "\n",
    "To make use of multiple augmentation, `sequential` and `sometimes` pipelines are introduced to connect augmenters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply different augmenters sequentially"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before:  ['The', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog']\n",
      "after:  ['lThe', 'uquick', 'browDn', 'fAox', 'ljumps', 'ojver', 'th$e', 'laTzy', 'Zdog']\n",
      "tokens: 9 ['lThe', 'uquick', 'browDn', 'fAox', 'ljumps', 'ojver', 'th$e', 'laTzy', 'Zdog']\n",
      "results: 7 ['lThe', 'uquick', 'browDn', 'fAox', 'ojver', 'th$e', 'laTzy']\n",
      "after:  ['lThe', 'uquick', 'browDn', 'fAox', 'ojver', 'th$e', 'laTzy']\n",
      "['The', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog'] --> ['lThe', 'uquick', 'browDn', 'fAox', 'ojver', 'th$e', 'laTzy']\n"
     ]
    }
   ],
   "source": [
    "aug = naf.Sequential([\n",
    "    nac.RandomCharAug(action=Action.INSERT),\n",
    "    naw.RandomWordAug()\n",
    "])\n",
    "\n",
    "print('{} --> {}'.format(tokens, aug.augment(tokens)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply some augmenters randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before:  ['The', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog']\n",
      "after:  ['Thve', 'qtuick', 'ibrown', 'fwox', '$jumps', 'oKver', 'tGhe', 'l2azy', 'Ddog']\n",
      "tokens: 9 ['Thve', 'qtuick', 'ibrown', 'fwox', '$jumps', 'oKver', 'tGhe', 'l2azy', 'Ddog']\n",
      "results: 7 ['qtuick', 'ibrown', 'fwox', '$jumps', 'oKver', 'tGhe', 'l2azy']\n",
      "after:  ['Qtuick', 'ibrown', 'fwox', '$jumps', 'oKver', 'tGhe', 'l2azy']\n",
      "['The', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog'] --> ['Qtuick', 'ibrown', 'fwox', '$jumps', 'oKver', 'tGhe', 'l2azy']\n"
     ]
    }
   ],
   "source": [
    "aug = naf.Sequential([\n",
    "    nac.RandomCharAug(action=Action.INSERT),\n",
    "    naw.RandomWordAug()\n",
    "])\n",
    "\n",
    "print('{} --> {}'.format(tokens, aug.augment(tokens)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
